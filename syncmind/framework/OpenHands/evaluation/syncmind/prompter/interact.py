"""
Functions for using OpenAI API for LLM interaction
"""

import os
from typing import List
from litellm import completion as litellm_completion


def llm_interaction(
        model_name: str, 
        messages: List, 
        api_key: str = None, 
        base_url: str = None, 
        api_version: str = None,
        temperature: float = 0.7, 
        max_tokens: int = 1000
    ):
    """
    Interacts with various LLMs using litellm and returns the response.

    Args:
        model_name (str): The name of the language model (e.g., "gpt-4", "llama", "deepseek").
        messages (list): A list of messages as a conversation context, with role and content fields.
        api_key (str, optional): API key for accessing the LLM provider. Defaults to None.
        temperature (float, optional): Sampling temperature for response randomness. Defaults to 0.7.
        max_tokens (int, optional): Maximum number of tokens to generate in the response. Defaults to 100.

    Returns:
        str: The response generated by the model.
    """
    try:
        response = litellm_completion(
            model=model_name,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
            api_key=api_key,
            base_url=base_url,
            api_version=api_version,
            stop=None
        )
        # Assuming the API returns the response in `text` field
        return response
    except Exception as e:
        return f"Error occurred: {str(e)}"

def openai_api_qa_interaction(llm_config, prompt_list):
    """Know-everything collaborator"""
    agent_name = 'gpt-4o'
    try:
        response = llm_interaction(
            model_name=agent_name,
            messages=prompt_list,
            api_key = llm_config.api_key,
        )
        processed_response = response.choices[0].message.content.strip()
        cost = response._hidden_params["response_cost"]
        # TODO: feel free to comment out if doesn't need to collect usage
        with open("./evaluation/syncmind/tmps/collaboration_cost.txt", "a+") as file:
            file.write(f"""\n[Model: {agent_name}] Collaborator assistance cost: $ {cost}""")

    except Exception as e:
        print(f"Exception occurred when running OpenAI API: {e}")
        raise
    return processed_response
    